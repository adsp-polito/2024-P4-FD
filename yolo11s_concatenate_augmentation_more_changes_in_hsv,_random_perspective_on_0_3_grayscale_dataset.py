# -*- coding: utf-8 -*-
"""Yolo11S - Concatenate Augmentation - More Changes in HSV, Random Perspective on 0.3 GrayScale Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IuSHOxoFk1u2N8m46iIFn4derrNwQcWc
"""

from google.colab import drive
drive.mount("/content/drive")

import os
# Base path to the dataset
dataset_path= '/content/drive/MyDrive/ADSP P4 - Foosball Detection/Big foosball detection dataset.v2i.yolov11'
# Paths to train images and labels
images_path = os.path.join(dataset_path, 'train/images')
labels_path = os.path.join(dataset_path, 'train/labels')

# List all image files
image_files = [f for f in os.listdir(images_path) if f.endswith(('.png', '.jpg', '.jpeg'))]

# Match images with their labels
image_label_pairs = []
for img_file in image_files:
    label_file = img_file.rsplit('.', 1)[0] + '.txt'  # Replace image extension with .txt
    label_path = os.path.join(labels_path, label_file)
    if os.path.exists(label_path):  # Ensure the label file exists
        image_label_pairs.append((os.path.join(images_path, img_file), label_path))

import cv2

# Loop through matched image-label pairs
for img_path, label_path in image_label_pairs[:5]:  # Limit to 5 pairs for display
    # Read the image
    img = cv2.imread(img_path)

    # Read the label
    with open(label_path, 'r') as file:
        label_data = file.readlines()

    # Print details
    print(f"Image Path: {img_path}")
    print(f"Label Path: {label_path}")
    print(f"Label Data: {label_data}")

    # Display the image (for local environments; not recommended in Colab)
    # cv2.imshow("Image", img)

import os
import cv2
import random
import math
import numpy as np
import matplotlib.pyplot as plt

def apply_random_hsv(image_bgr, hsv_h=0.25, hsv_s=0.9, hsv_v=0.5):
    """
    Apply YOLO-like random HSV shifts:
    image_bgr: BGR image (OpenCV format).
    hsv_h, hsv_s, hsv_v: maximum random shifts for hue, saturation, value.
    """
    hsv_img = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV).astype(np.float32)

    # Random gains
    h_gain = random.uniform(-hsv_h, hsv_h) * 180
    s_gain = random.uniform(-hsv_s, hsv_s)
    v_gain = random.uniform(-hsv_v, hsv_v)

    hsv_img[..., 0] = (hsv_img[..., 0] + h_gain) % 180
    hsv_img[..., 1] *= (1 + s_gain)
    hsv_img[..., 2] *= (1 + v_gain)

    # Clip
    hsv_img[..., 1] = np.clip(hsv_img[..., 1], 0, 255)
    hsv_img[..., 2] = np.clip(hsv_img[..., 2], 0, 255)

    hsv_img = hsv_img.astype(np.uint8)
    aug_bgr = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2BGR)
    return aug_bgr

def apply_random_perspective(img_bgr, degrees=15.0, translate=0.2, scale=0.5,
                             shear=5.0, perspective=0.002):
    """
    Apply random perspective/affine transformations:
    - rotation ±degrees
    - translation ±translate
    - scale ±scale
    - shear ±shear
    - perspective (small warp)
    """
    height, width = img_bgr.shape[:2]

    # Rotation
    angle = random.uniform(-degrees, degrees)

    # Scale factor
    scale_factor = 1.0 + random.uniform(-scale, scale)  # e.g. 1 ± 0.5 => [0.5, 1.5]

    # Shear
    shear_x = random.uniform(-shear, shear)
    shear_y = random.uniform(-shear, shear)

    # Translate
    tx = random.uniform(-translate, translate) * width
    ty = random.uniform(-translate, translate) * height

    # Build rotation+scale around center
    center = (width / 2, height / 2)
    M = cv2.getRotationMatrix2D(center, angle, scale_factor)

    # Incorporate shear into M (simple approach)
    M[0,1] += shear_x * 0.001
    M[1,0] += shear_y * 0.001

    # Translate
    M[0,2] += tx
    M[1,2] += ty

    # Possible random perspective warp
    persp_val = random.uniform(0, perspective)
    if persp_val > 0:
        # 4 corners
        pts1 = np.float32([[0,0],[width,0],[0,height],[width,height]])
        offset = persp_val * max(width, height)
        pts2 = np.float32([
            [0 + random.uniform(-offset,offset),   0 + random.uniform(-offset,offset)],
            [width + random.uniform(-offset,offset), 0 + random.uniform(-offset,offset)],
            [0 + random.uniform(-offset,offset),   height + random.uniform(-offset,offset)],
            [width + random.uniform(-offset,offset), height + random.uniform(-offset,offset)]
        ])
        H = cv2.getPerspectiveTransform(pts1, pts2)
        warped = cv2.warpPerspective(img_bgr, H, (width, height), borderMode=cv2.BORDER_REFLECT_101)
        return warped
    else:
        # Just affine
        warped = cv2.warpAffine(img_bgr, M, (width, height), borderMode=cv2.BORDER_REFLECT_101)
        return warped

def show_augmented_samples(image_dir, n=20,
                           hsv_h=0.25, hsv_s=0.9, hsv_v=0.5,
                           degrees=15.0, translate=0.2, scale=0.5,
                           shear=5.0, perspective=0.002):
    """
    Display side-by-side original vs. augmented images (for n samples).
    Combines random HSV + random perspective transforms.
    """
    valid_exts = ('.jpg', '.jpeg', '.png')
    all_images = [f for f in os.listdir(image_dir) if f.lower().endswith(valid_exts)]
    if not all_images:
        print(f"No images found in {image_dir}")
        return

    random.shuffle(all_images)
    samples = all_images[:n]

    fig, axs = plt.subplots(len(samples), 2, figsize=(10, 5 * len(samples)))
    if len(samples) == 1:
        axs = [axs]  # Make iterable if there's only one sample

    for i, img_file in enumerate(samples):
        img_path = os.path.join(image_dir, img_file)
        original_bgr = cv2.imread(img_path)
        if original_bgr is None:
            continue

        # 1) Apply random HSV
        aug_bgr = apply_random_hsv(original_bgr, hsv_h, hsv_s, hsv_v)

        # 2) Apply random perspective
        aug_bgr = apply_random_perspective(aug_bgr, degrees, translate, scale, shear, perspective)

        # Convert BGR -> RGB for display
        original_rgb = cv2.cvtColor(original_bgr, cv2.COLOR_BGR2RGB)
        augmented_rgb = cv2.cvtColor(aug_bgr, cv2.COLOR_BGR2RGB)

        # Display side by side
        axs[i][0].imshow(original_rgb)
        axs[i][0].set_title(f"Original: {img_file}")
        axs[i][0].axis('off')

        axs[i][1].imshow(augmented_rgb)
        axs[i][1].set_title("Augmented")
        axs[i][1].axis('off')

    plt.tight_layout()
    plt.show()

# Example usage:
train_images_dir = "/content/drive/MyDrive/ADSP P4 - Foosball Detection/Big foosball detection dataset for Yolo11s - Grayscale offline Augmentation/train/images"

show_augmented_samples(
    image_dir=train_images_dir,
    n=20,
    hsv_h=0.25, hsv_s=0.9, hsv_v=0.5,  # Hue shift increased to ±25%
    degrees=15.0, translate=0.2, scale=0.5,
    shear=5.0, perspective=0.002
)

# Commented out IPython magic to ensure Python compatibility.
# Install necessary libraries
!pip install ultralytics --upgrade
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Import libraries
from ultralytics import YOLO
from torch.utils.tensorboard import SummaryWriter
import csv
import os

# Paths
model_path = '/content/drive/MyDrive/ADSP P4 - Foosball Detection/Yolo Models/yolo11s.pt'
data_yaml_path = '/content/drive/MyDrive/ADSP P4 - Foosball Detection/Big foosball detection dataset for Yolo11s - Grayscale offline Augmentation/data.yaml'
log_dir = '/content/drive/MyDrive/ADSP P4 - Foosball Detection/runs/tensorboard_logs_Augmented_HSV_Random_Perspective'
results_file = '/content/drive/MyDrive/ADSP P4 - Foosball Detection/runs/results_Augmented_HSV_Random_Perspective.csv'

# Ensure the results directory exists
results_dir = os.path.dirname(results_file)
if not os.path.exists(results_dir):
    os.makedirs(results_dir)

# Initialize YOLO model
model = YOLO(model_path)

# Create a results CSV file and write the header (if it doesn't exist)
if not os.path.exists(results_file):
    with open(results_file, mode='w', newline='') as file:
        writer_csv = csv.writer(file)
        writer_csv.writerow(['epoch', 'box_loss', 'cls_loss', 'obj_loss', 'mAP50', 'mAP50_95'])

# Custom callback function to log metrics to CSV and TensorBoard
def custom_callback(epoch, metrics):
    print(f"Epoch {epoch + 1} metrics: {metrics}")
    writer.add_scalar('Loss/box_loss', metrics.box_loss, epoch)
    writer.add_scalar('Loss/cls_loss', metrics.cls_loss, epoch)
    writer.add_scalar('Loss/obj_loss', metrics.obj_loss, epoch)
    writer.add_scalar('Metrics/mAP50', metrics.map50, epoch)
    writer.add_scalar('Metrics/mAP50_95', metrics.map, epoch)

    with open(results_file, mode='a', newline='') as file:
        writer_csv = csv.writer(file)
        writer_csv.writerow([
            epoch + 1,
            metrics.box_loss,
            metrics.cls_loss,
            metrics.obj_loss,
            metrics.map50,
            metrics.map
        ])

# Initialize TensorBoard writer
writer = SummaryWriter(log_dir)

# Train the YOLO model with stronger random perspective + HSV augmentations
results = model.train(
    data=data_yaml_path,
    epochs=40,
    imgsz=640,
    project=log_dir,
    name='yolo11s_training',
    device=0,  # Use GPU if available

    # More aggressive perspective parameters
    degrees=15.0,      # rotate ±15 degrees
    translate=0.2,     # translate ±20% of image
    scale=0.5,         # zoom range (0.5 - 1.5)
    shear=5.0,         # shear ±5 degrees
    perspective=0.002, # perspective distortion

    # Stronger color augmentation parameters
    hsv_h=0.25,        # ±20% hue shift
    hsv_s=0.9,         # ±90% saturation
    hsv_v=0.5          # ±50% brightness
)

# Close the TensorBoard writer after training
writer.close()

# Launch TensorBoard to visualize training progress
# %load_ext tensorboard
# %tensorboard --logdir /content/drive/MyDrive/ADSP P4 - Foosball Detection/runs/tensorboard_logs_Augmented_HSV_Random_Perspective

#decreasing the brightness and increasing the contrast of the LINKS frames.
import cv2
import os
import numpy as np
import matplotlib.pyplot as plt
from glob import glob

def adjust_brightness_contrast(image, brightness=0, contrast=1.0):
    """
    Adjusts brightness and contrast of an image.

    :param image: Input image in BGR format.
    :param brightness: Integer from -255 to 255.
    :param contrast: Float from 0.0 to 3.0.
    :return: Adjusted image.
    """
    # Convert image to float to prevent clipping values
    img = image.astype(np.float32)

    # Apply contrast
    img = img * contrast

    # Apply brightness
    img = img + brightness

    # Clip the values to [0,255] and convert back to uint8
    img = np.clip(img, 0, 255).astype(np.uint8)

    return img

def process_images(input_dir, output_dir, brightness=0, contrast=1.0):
    """
    Processes all images in the input directory by adjusting brightness and contrast.

    :param input_dir: Directory containing input images.
    :param output_dir: Directory to save processed images.
    :param brightness: Integer from -255 to 255.
    :param contrast: Float from 0.0 to 3.0.
    :return: List of processed image paths.
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"Created output directory: {output_dir}")

    # Supported image extensions
    extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']

    # Gather all image paths
    image_paths = []
    for ext in extensions:
        image_paths.extend(glob(os.path.join(input_dir, f'*{ext}')))

    if not image_paths:
        print("No images found in the input directory.")
        return []

    processed_image_paths = []

    for img_path in image_paths:
        # Read the image
        img = cv2.imread(img_path)
        if img is None:
            print(f"Warning: Unable to read {img_path}. Skipping.")
            continue

        # Adjust brightness and contrast
        processed_img = adjust_brightness_contrast(img, brightness, contrast)

        # Save the processed image
        filename = os.path.basename(img_path)
        save_path = os.path.join(output_dir, filename)
        cv2.imwrite(save_path, processed_img)
        processed_image_paths.append(save_path)

    print(f"Processed {len(processed_image_paths)} images.")
    return processed_image_paths

def display_image_samples(image_paths, num_samples=20):
    """
    Displays a grid of image samples.

    :param image_paths: List of image file paths to display.
    :param num_samples: Number of samples to display.
    """
    if not image_paths:
        print("No images to display.")
        return

    # Limit to the number of available images
    num_samples = min(num_samples, len(image_paths))

    # Determine grid size
    cols = 5
    rows = (num_samples + cols - 1) // cols

    plt.figure(figsize=(15, 3 * rows))

    for i in range(num_samples):
        img_path = image_paths[i]
        img = cv2.imread(img_path)
        if img is None:
            print(f"Warning: Unable to read {img_path}. Skipping.")
            continue
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        plt.subplot(rows, cols, i + 1)
        plt.imshow(img_rgb)
        plt.axis('off')
        plt.title(os.path.basename(img_path))

    plt.tight_layout()
    plt.show()

def main():
    # Define the input and output directories
    # Replace these paths with your actual directories
    input_dir = r'/content/drive/MyDrive/ADSP P4 - Foosball Detection/Frames Extracted from Links videos'
    output_dir = r"/content/drive/MyDrive/ADSP P4 - Foosball Detection/Processed Frames Extracted from Link's videos"

    # Define brightness and contrast adjustments
    # To decrease brightness, use a negative value
    # To increase contrast, use a value greater than 1
    brightness = -114.75    # Decrease brightness by 114.75 ~ 45%
    contrast = 1.5      # Increase contrast by 1.5 times

    print("Starting image processing...")
    processed_images = process_images(input_dir, output_dir, brightness, contrast)

    print("\nDisplaying 20 sample processed images:")
    display_image_samples(processed_images, num_samples=20)

if __name__ == "__main__":
    # If using Google Colab, ensure Google Drive is mounted before running main()
    # Example:
    # from google.colab import drive
    # drive.mount('/content/drive')

    main()

# Test results on LINKS
# Install the ultralytics library
!pip install ultralytics --upgrade

import os
import time
from ultralytics import YOLO
from IPython.display import Image, display

# 1) Load the trained model
model_path = '/content/drive/MyDrive/ADSP P4 - Foosball Detection/runs/tensorboard_logs_Augmented_HSV_Random_Perspective/yolo11s_training3/weights/best.pt'  # Adjust if needed
model = YOLO(model_path)

# 2) Define the test images path and the results directory
test_images_path = "/content/drive/MyDrive/ADSP P4 - Foosball Detection/Videos from Links"
results_dir = '/content/drive/MyDrive/ADSP P4 - Foosball Detection/runs/test_on_Augmented_HSV_Random_Perspective'

# 3) Count how many images will be processed
valid_exts = ('.jpg', '.jpeg', '.png')
test_files = [f for f in os.listdir(test_images_path) if f.lower().endswith(valid_exts)]
num_images = len(test_files)

# 4) Run inference on test images and measure time
start_time = time.time()

results = model.predict(
    source=test_images_path,
    imgsz=640,           # Image size for inference
    conf=0.25,           # Confidence threshold
    save=True,           # Save predictions (images and text)
    project='/content/drive/MyDrive/test_results',  # Directory for all results
    name='test_predictions- Yolo11S - Augmented_HSV_Random_Perspective_40 epochs + more brightness and contrast changes in Links Frams'                          # Subdirectory for this run
)

end_time = time.time()
total_time = end_time - start_time

# 5) Calculate FPS
fps = num_images / total_time if total_time > 0 else 0.0

# 6) Print the FPS result
print(f"[INFO] Total images processed: {num_images}")
print(f"[INFO] Total inference time: {total_time:.2f} s")
print(f"[INFO] Approx FPS: {fps:.2f}")

# 7) Display the predicted images
print(f"\nPredicted results saved in: {results_dir}")
for image_name in os.listdir(results_dir):
    if image_name.lower().endswith('.jpg'):
        display(Image(filename=os.path.join(results_dir, image_name)))

#Test on the new augmented Yolo11s 10 epoch trained.

# 1) Install or upgrade the necessary libraries
!pip install ultralytics xlsxwriter --upgrade

import csv
import os
import time
import torch
import xlsxwriter
import random
import glob
from ultralytics import YOLO
from IPython.display import display
from PIL import Image as PILImage
import cv2
import numpy as np

# ======================================
# 1) CONFIGURATION
# ======================================
model_weights = '/content/drive/MyDrive/ADSP P4 - Foosball Detection/Yolo11s-Augmented-Best-10 epochs/best.pt'
data_yaml_path = '/content/drive/MyDrive/ADSP P4 - Foosball Detection/Big foosball detection dataset.v2i.yolov11/data.yaml'

# Path to your test images folder
test_images_dir = '/content/drive/MyDrive/ADSP P4 - Foosball Detection/Big foosball detection dataset.v2i.yolov11/test/images'

# ======================================
# 2) LOAD MODEL
# ======================================
model = YOLO(model_weights)

# ======================================
# 3) VALIDATE ON THE ENTIRE TEST SET
#    We measure the time it takes to process all test images.
# ======================================
start_time = time.time()

results = model.val(
    data=data_yaml_path,
    split='test',   # Evaluate on 'test' split
    batch=1,        # Adjust if you have more GPU memory
    imgsz=640,
    device=0 if torch.cuda.is_available() else 'cpu'
)

end_time = time.time()
total_time = end_time - start_time

# ======================================
# 4) MANUALLY COUNT IMAGES IN TEST FOLDER & CALCULATE FPS
# ======================================
# Count all .jpg, .jpeg, .png files in the test_images_dir
valid_exts = ('*.jpg', '*.jpeg', '*.png')
all_test_images = []
for ext in valid_exts:
    all_test_images.extend(glob.glob(os.path.join(test_images_dir, ext)))

total_images = len(all_test_images)

fps = total_images / total_time if total_time > 0 else 0.0

print(f"\n[INFO] Validation on entire test set completed.")
print(f"[INFO] (Manual) Number of test images in directory: {total_images}")
print(f"[INFO] Total validation time: {total_time:.2f} s")
print(f"[INFO] Approx FPS (our custom calculation): {fps:.2f}")

# ======================================
# 5) (OPTIONAL) DISPLAY 20 EXAMPLE IMAGES WITH PREDICTIONS
#    This step is not timed for the FPS calculation—just a quick demo.
# ======================================
img_files = [f for f in os.listdir(test_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
random.shuffle(img_files)
sample_images = img_files[:20]

print("\n[INFO] Displaying predictions for 20 random images.")

for img_file in sample_images:
    img_path = os.path.join(test_images_dir, img_file)
    # Run inference (predict) on this single image
    pred_result = model.predict(source=img_path, conf=0.25, save=False, imgsz=640)

    # Convert the predicted BGR image to RGB
    pred_img_bgr = pred_result[0].plot()
    pred_img_rgb = cv2.cvtColor(pred_img_bgr, cv2.COLOR_BGR2RGB)

    # Convert to PIL and display
    pil_img = PILImage.fromarray(pred_img_rgb)
    display(pil_img)

print("\n[INFO] Done displaying up to 20 example predictions.")

# Test on the original Yolo11s 10 epoch trained.
# 1) Install or upgrade the necessary libraries
!pip install ultralytics xlsxwriter --upgrade

import csv
import os
import time
import torch
import xlsxwriter
import random
import glob
from ultralytics import YOLO
from IPython.display import display
from PIL import Image as PILImage
import cv2
import numpy as np

# ======================================
# 1) CONFIGURATION
# ======================================
model_weights = '/content/drive/MyDrive/ADSP P4 - Foosball Detection/Yolo11s - Best - 10 epochs/best.pt'
data_yaml_path = '/content/drive/MyDrive/ADSP P4 - Foosball Detection/Big foosball detection dataset.v2i.yolov11/data.yaml'

# Path to your test images folder
test_images_dir = '/content/drive/MyDrive/ADSP P4 - Foosball Detection/Big foosball detection dataset.v2i.yolov11/test/images'

# ======================================
# 2) LOAD MODEL
# ======================================
model = YOLO(model_weights)

# ======================================
# 3) VALIDATE ON THE ENTIRE TEST SET
#    We measure the time it takes to process all test images.
# ======================================
start_time = time.time()

results = model.val(
    data=data_yaml_path,
    split='test',   # Evaluate on 'test' split
    batch=1,        # Adjust if you have more GPU memory
    imgsz=640,
    device=0 if torch.cuda.is_available() else 'cpu'
)

end_time = time.time()
total_time = end_time - start_time

# ======================================
# 4) MANUALLY COUNT IMAGES IN TEST FOLDER & CALCULATE FPS
# ======================================
# Count all .jpg, .jpeg, .png files in the test_images_dir
valid_exts = ('*.jpg', '*.jpeg', '*.png')
all_test_images = []
for ext in valid_exts:
    all_test_images.extend(glob.glob(os.path.join(test_images_dir, ext)))

total_images = len(all_test_images)

fps = total_images / total_time if total_time > 0 else 0.0

print(f"\n[INFO] Validation on entire test set completed.")
print(f"[INFO] (Manual) Number of test images in directory: {total_images}")
print(f"[INFO] Total validation time: {total_time:.2f} s")
print(f"[INFO] Approx FPS (our custom calculation): {fps:.2f}")

# ======================================
# 5) (OPTIONAL) DISPLAY 20 EXAMPLE IMAGES WITH PREDICTIONS
#    This step is not timed for the FPS calculation—just a quick demo.
# ======================================
img_files = [f for f in os.listdir(test_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
random.shuffle(img_files)
sample_images = img_files[:20]

print("\n[INFO] Displaying predictions for 20 random images.")

for img_file in sample_images:
    img_path = os.path.join(test_images_dir, img_file)
    # Run inference (predict) on this single image
    pred_result = model.predict(source=img_path, conf=0.25, save=False, imgsz=640)

    # Convert the predicted BGR image to RGB
    pred_img_bgr = pred_result[0].plot()
    pred_img_rgb = cv2.cvtColor(pred_img_bgr, cv2.COLOR_BGR2RGB)

    # Convert to PIL and display
    pil_img = PILImage.fromarray(pred_img_rgb)
    display(pil_img)

print("\n[INFO] Done displaying up to 20 example predictions.")